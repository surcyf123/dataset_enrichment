# cd dataset_enrichment/enrichment_pipeline/deploy_pipeline/ && conda activate pytorch && python3 deploy_instance_and_model.py


models_left_to_test = [

"TheBloke/Baichuan2-13B-Chat-GPTQ",
"TheBloke/Vicuna-13B-CoT-GPTQ",
"TheBloke/chronos-hermes-13B-GPTQ",
"TheBloke/minotaur-13B-fixed-GPTQ",
"TheBloke/Carl-13B-GPTQ",
"TheBloke/Scarlett-13B-GPTQ",
"TheBloke/guanaco-13B-GPTQ",
"TheBloke/vicuna-13b-v1.3.0-GPTQ",
"TheBloke/airoboros-13B-1.1-GPTQ",
"TheBloke/airoboros-13B-gpt4-1.3-GPTQ",
"TheBloke/wizardLM-13B-1.0-GPTQ",
"TheBloke/airoboros-13b-gpt4-GPTQ",
"TheBloke/OpenOrca-Preview1-13B-GPTQ",
"TheBloke/Hermes-LLongMA-2-7B-8K-GPTQ",
"TheBloke/AlpacaCielo-13B-GPTQ",
"TheBloke/chronos-wizardlm-uc-scot-st-13B-GPTQ",
"TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ",
"TheBloke/Hermes-LLongMA-2-13B-8K-GPTQ",
"TheBloke/Asclepius-13B-GPTQ",
"TheBloke/airoboros-13b-gpt4-1.4-SuperHOT-8K-GPTQ",
"TheBloke/CodeLlama-13B-Instruct-GPTQ",
"TheBloke/GPT4All-13B-snoozy-GPTQ",
"TheBloke/gpt4-x-vicuna-13B-GPTQ",
"TheBloke/Vicuna-13B-v1.3-German-GPTQ",
"TheBloke/CodeLlama-13B-Python-GPTQ",
"TheBloke/airoboros-13B-gpt4-1.2-GPTQ",
"TheBloke/CAMEL-13B-Role-Playing-Data-GPTQ",
"TheBloke/robin-13B-v2-GPTQ",]